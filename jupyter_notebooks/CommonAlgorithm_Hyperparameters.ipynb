{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Most Coomon Hyperparameters for Algorithms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Reference guide to common hyperparameters for Algorithms\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "\n",
        "params_search = {\n",
        "    \"LogisticRegression\":{'model__penalty': [\"l2\",\"l1\", \"elasticnet\"],\n",
        "                          'model__C': [1, 0.5, 2],\n",
        "                          'model__tol': [1e-4,1e-3,1e-5],\n",
        "                            }\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "params_search = {\n",
        "    \"DecisionTreeClassifier\":{'model__max_depth': [None,4, 15],\n",
        "                              'model__min_samples_split': [2,50],\n",
        "                              'model__min_samples_leaf': [1,50],\n",
        "                              'model__max_leaf_nodes': [None,50],\n",
        "                            }\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "params_search = {\n",
        "    \"DecisionTreeRegressor\":{'model__max_depth': [None,4, 15],\n",
        "                             'model__min_samples_split': [2,50],\n",
        "                             'model__min_samples_leaf': [1,50],\n",
        "                             'model__max_leaf_nodes': [None,50],\n",
        "                            }\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Rnndom Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "params_search = {\n",
        "    \"RandomForestRegressor\":{'model__n_estimators': [100,50, 140],\n",
        "                             'model__max_depth': [None,4, 15],\n",
        "                             'model__min_samples_split': [2,50],\n",
        "                             'model__min_samples_leaf': [1,50],\n",
        "                             'model__max_leaf_nodes': [None,50],\n",
        "                            }\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "params_search = {\n",
        "    \"RandomForestClassifier\":{'model__n_estimators': [100,50,140],\n",
        "                             'model__max_depth': [None,4, 15],\n",
        "                             'model__min_samples_split': [2,50],\n",
        "                             'model__min_samples_leaf': [1,50],\n",
        "                             'model__max_leaf_nodes': [None,50],\n",
        "                            }\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gradient Boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
        "from sklearn.ensemble import GradientBoostingClassifier \n",
        "\n",
        "params_search = {\n",
        "    \"GradientBoostingClassifier\":{'model__n_estimators': [100,50,140],\n",
        "                                  'model__learning_rate':[0.1, 0.01, 0.001],\n",
        "                                  'model__max_depth': [3,15, None],\n",
        "                                  'model__min_samples_split': [2,50],\n",
        "                                  'model__min_samples_leaf': [1,50],\n",
        "                                  'model__max_leaf_nodes': [None,50],\n",
        "                            }\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "params_search = {\n",
        "    \"GradientBoostingRegressor\":{'model__n_estimators': [100,50,140],\n",
        "                                  'model__learning_rate':[0.1, 0.01, 0.001],\n",
        "                                  'model__max_depth': [3,15, None],\n",
        "                                  'model__min_samples_split': [2,50],\n",
        "                                  'model__min_samples_leaf': [1,50],\n",
        "                                  'model__max_leaf_nodes': [None,50],\n",
        "                            }\n",
        "  }\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "params_search = {\n",
        "    \"AdaBoostClassifier\":{'model__n_estimators': [50,25,80,150],\n",
        "                          'model__learning_rate':[1,0.1, 2],\n",
        "                            }\n",
        "  }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "\n",
        "params_search = {\n",
        "    \"AdaBoostRegressor\":{'model__n_estimators': [50,25,80,150],\n",
        "                          'model__learning_rate':[1,0.1, 2],\n",
        "                          'model__loss':['linear', 'square', 'exponential'],\n",
        "                            }\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### XG Boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "params_search = {\n",
        "    \"XGBRegressor\":{'model__n_estimators': [30,80,200],\n",
        "                    'model__max_depth': [None, 3, 15],\n",
        "                    'model__learning_rate': [0.01,0.1,0.001],\n",
        "                    'model__gamma': [0, 0.1],\n",
        "                            }\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "params_search = {\n",
        "    \"XGBClassifier\":{'model__n_estimators': [30,80,200],\n",
        "                      'model__max_depth': [None, 3, 15],\n",
        "                      'model__learning_rate': [0.01,0.1,0.001],\n",
        "                      'model__gamma': [0, 0.1],\n",
        "                            }\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extra Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "params_search = {\n",
        "    \"ExtraTreesClassifier\":{'model__n_estimators': [100,50,150],\n",
        "                          'model__max_depth': [None, 3, 15],\n",
        "                          'model__min_samples_split': [2, 50],\n",
        "                          'model__min_samples_leaf': [1,50],\n",
        "                            }\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "\n",
        "params_search = {\n",
        "    \"ExtraTreesRegressor\":{'model__n_estimators': [100,50,150],\n",
        "                          'model__max_depth': [None, 3, 15],\n",
        "                          'model__min_samples_split': [2, 50],\n",
        "                          'model__min_samples_leaf': [1,50],\n",
        "                            }\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Support Vector Machine (SVM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Support Vector Machine (or SVM) is an algorithm that can be used for Classification or Regression\n",
        "\n",
        "* The idea is to find a hyperplane that separates the data.\n",
        "* A hyperplane is a boundary that distinguishes the data points and will be N-1 dimensional. For example, if you have two variables (2 dimensions), you can plot these variables in an XY plot, like a 2D scatter plot. Your hyperplane, in this case, is a line. If you have 3 variables (3 dimensions), you can plot these variables in an XYZ plot, like a 3D scatter plot. \n",
        "* The hyperplane should have the maximum distance (here called the margin) between data points. Support vectors (therefore, the algorithm name) are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "params_search = {\n",
        "    \"SVC\": {#'model__C':[1,0.5,1.5],\n",
        "          'model__tol':[1e-3,1e-2,1e-4],\n",
        "          #  'model__kernel': ['rbf', 'poly', 'sigmoid'],\n",
        "            }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Linear Support Vector Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "According to its documentation, a Linear Support Vector Machine is similar to an SVC with a parameter kernel=’linear’. However, it is implemented using liblinear rather than libsvm, so it has more flexibility in choosing penalties and loss functions. Thus, it should scale better to large numbers of samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "params_search = {\n",
        "\n",
        "    \"LinearSVC\": {#'model__C':[1,0.5,1.5],\n",
        "                  'model__tol':[1e-3,1e-2,1e-4],\n",
        "                  },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Linear classifier with SGD (Stochastic Gradient Descent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "According to Scikit-learn documentation, this estimator implements regularised linear models (SVM, logistic regression, etc.) with stochastic gradient descent (SGD) learning.\n",
        "\n",
        "* SGD is a simple yet very efficient approach to fitting linear classifiers and regressors under convex loss functions such as (linear) Support Vector Machines and Logistic Regression. SGD is merely an optimisation technique and does not correspond to a specific family of machine learning models. It is only a way to train a model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "params_search = {\n",
        "    \"SGDClassifier\": {'model__tol':[1e-3, 1e-2, 1e-4],\n",
        "                    #  'model__penalty':['l2', 'l1', 'elasticnet'],\n",
        "                     # 'model__alpha':[0.0001,0.001],\n",
        "                      },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "According to Scikit-learn [documentation](https://scikit-learn.org/stable/modules/naive_bayes.html), Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of features given the value of the class variable.\n",
        "\n",
        "* Naive Bayes learners and classifiers can be extremely fast compared to more sophisticated methods. The decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one-dimensional distribution. This, in turn, helps to alleviate problems stemming from the curse of dimensionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "params_search = {\n",
        "    \"MultinomialNB\":{'model__alpha': [1.0, 0.6, 0.4, 1.3, 0.0]\n",
        "                     },\n",
        "}\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv (3.12.8)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
