{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Scikit-learn - Cross Validation Search (GridSearchCV) and Hyperparameter Optimisation Multiple Clf**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Learn and use GridSearchCV for Hyperparameter Optimisation with mulitple classifiers\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Hyperparameter Optimisation with one algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "### Multiclass classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "We are going to consider a similar workflow as with other ML operations:\n",
        "\n",
        "* Split the data\n",
        "* Define the pipeline and hyperparameters\n",
        "* Fit the pipeline\n",
        "* Evaluate the pipeline\n",
        "\n",
        "We load the iris dataset for this exercise. It contains records of three species or classes of iris plants, with their petal and sepal measurements and split into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(150, 5)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width species\n",
              "0           5.1          3.5           1.4          0.2  setosa\n",
              "1           4.9          3.0           1.4          0.2  setosa\n",
              "2           4.7          3.2           1.3          0.2  setosa\n",
              "3           4.6          3.1           1.5          0.2  setosa\n",
              "4           5.0          3.6           1.4          0.2  setosa"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#load iris dataset\n",
        "df_clf = sns.load_dataset('iris')\n",
        "\n",
        "print(df_clf.shape)\n",
        "df_clf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Train set: (120, 4) (120,) \n",
            "* Test set: (30, 4) (30,)\n"
          ]
        }
      ],
      "source": [
        "#split the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test,y_train, y_test = train_test_split(\n",
        "                                    df_clf.drop(['species'],axis=1),\n",
        "                                    df_clf['species'],\n",
        "                                    test_size=0.2,\n",
        "                                    random_state=101\n",
        "                                    )\n",
        "\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a pipeline using three steps: feature scaling, feature selection and modelling with RandomForestClassifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def pipeline_clf():\n",
        "  pipeline = Pipeline([\n",
        "      ( \"feat_scaling\",StandardScaler() ),\n",
        "      ( \"feat_selection\",SelectFromModel(RandomForestClassifier(random_state=101)) ),\n",
        "      ( \"model\", RandomForestClassifier(random_state=101)),\n",
        "\n",
        "    ])\n",
        "\n",
        "  return pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define our hyperparameter list based on the algorithm documentation.\n",
        "\n",
        "* In this case, there will be two hyperparameter combinations.\n",
        "* We will reduce the number of hyperparameter combinations so the code runs faster. (purely for example) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model__n_estimators': [10, 20]}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\"model__n_estimators\":[10,20],\n",
        "              }\n",
        "param_grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this project we are interested particularly in the Virginica species and we need the predictions for this class to be precise. This is an arbitrary choice, however, it is an example of the type of business requirements given to you by the product owner or business expert.\n",
        "\n",
        "* In this case, your scoring parameter is precision_score to the class Virginica.\n",
        "* In a Multiclass classification, when your performance metric is accuracy, you just pass scoring='accuracy' as an argument, as done with a binary classifier.\n",
        "* In our case, we need to pass arguments to the make_scorer() method to fine-tune the model using precision on the Virginica species. We pass to make_scorer as an argument the metric we want - precision_score. The next argument is labels, where you set the class you want to tune as a list. Note that in this dataset, the species is not encoded as numbers but as categories. If it were numbers, you would pass the number related to the class you want to tune. The last argument is average, and it should equal None since you compute the precision from one class only (in this case Virginica) and you don't need to average.\n",
        "* Finally, you fit the grid search to the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
              "             estimator=Pipeline(steps=[(&#x27;feat_scaling&#x27;, StandardScaler()),\n",
              "                                       (&#x27;feat_selection&#x27;,\n",
              "                                        SelectFromModel(estimator=RandomForestClassifier(random_state=101))),\n",
              "                                       (&#x27;model&#x27;,\n",
              "                                        RandomForestClassifier(random_state=101))]),\n",
              "             n_jobs=-2, param_grid={&#x27;model__n_estimators&#x27;: [10, 20]},\n",
              "             scoring=make_scorer(precision_score, labels=[&#x27;virginica&#x27;], average=None),\n",
              "             verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
              "             estimator=Pipeline(steps=[(&#x27;feat_scaling&#x27;, StandardScaler()),\n",
              "                                       (&#x27;feat_selection&#x27;,\n",
              "                                        SelectFromModel(estimator=RandomForestClassifier(random_state=101))),\n",
              "                                       (&#x27;model&#x27;,\n",
              "                                        RandomForestClassifier(random_state=101))]),\n",
              "             n_jobs=-2, param_grid={&#x27;model__n_estimators&#x27;: [10, 20]},\n",
              "             scoring=make_scorer(precision_score, labels=[&#x27;virginica&#x27;], average=None),\n",
              "             verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;feat_scaling&#x27;, StandardScaler()),\n",
              "                (&#x27;feat_selection&#x27;,\n",
              "                 SelectFromModel(estimator=RandomForestClassifier(random_state=101))),\n",
              "                (&#x27;model&#x27;, RandomForestClassifier(random_state=101))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">feat_selection: SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=RandomForestClassifier(random_state=101))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=101)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=101)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=101)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=2,\n",
              "             estimator=Pipeline(steps=[('feat_scaling', StandardScaler()),\n",
              "                                       ('feat_selection',\n",
              "                                        SelectFromModel(estimator=RandomForestClassifier(random_state=101))),\n",
              "                                       ('model',\n",
              "                                        RandomForestClassifier(random_state=101))]),\n",
              "             n_jobs=-2, param_grid={'model__n_estimators': [10, 20]},\n",
              "             scoring=make_scorer(precision_score, labels=['virginica'], average=None),\n",
              "             verbose=5)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the grid search and fit it to the training data showing precision for the Virginica species\n",
        "\n",
        "\n",
        "from sklearn.metrics import make_scorer, precision_score\n",
        "grid = GridSearchCV(estimator=pipeline_clf(),\n",
        "                    param_grid=param_grid,\n",
        "                    cv=2,\n",
        "                    n_jobs=-2,\n",
        "                    verbose=3, # In the workplace we typically set verbose to 1, \n",
        "                    # to reduce the number of messages when fitting the models.\n",
        "                    # For teaching purposes, we set it to 3 to see the score for each cross-validated model.\n",
        "                    scoring=make_scorer(precision_score,\n",
        "                                        labels=['virginica'],\n",
        "                                        average=None)\n",
        "                    )\n",
        "\n",
        "\n",
        "grid.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/2] END model__n_estimators=10; score=1.000\n",
            "[CV 2/2] END model__n_estimators=10; score=0.833\n",
            "[CV 1/2] END model__n_estimators=20; score=1.000\n",
            "[CV 2/2] END model__n_estimators=20; score=0.833\n"
          ]
        }
      ],
      "source": [
        "#display the results\n",
        "# Print per-fold scores in GridSearchCV verbose style\n",
        "# for i, params in enumerate(grid.cv_results_['params']):\n",
        "#     for fold in range(grid.cv):\n",
        "#         score = grid.cv_results_[f'split{fold}_test_virginica_precision'][i]\n",
        "#         print(f\"[CV {fold+1}/{grid.cv}] END {', '.join([f'{k}={v}' for k, v in params.items()])}; score={score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we check the results for all four different models with .cv_results_ .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[{'model__n_estimators': 10}, 0.9166666666666667],\n",
              "       [{'model__n_estimators': 20}, 0.9166666666666667]], dtype=object)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(pd.DataFrame(grid.cv_results_)\n",
        ".sort_values(by='mean_test_score',ascending=False)\n",
        ".filter(['params','mean_test_score'])\n",
        ".values\n",
        " )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model__n_estimators': 10}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#check best hyperparameters\n",
        "grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Pipeline(steps=[('feat_scaling', StandardScaler()),\n",
              "                 ('feat_selection',\n",
              "                  SelectFromModel(estimator=RandomForestClassifier(random_state=101))),\n",
              "                 ('model',\n",
              "                  RandomForestClassifier(n_estimators=10, random_state=101))]),\n",
              " 0.9166666666666667)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#check best pipeline\n",
        "pipeline = grid.best_estimator_\n",
        "#check best score\n",
        "best_score = grid.best_score_\n",
        "pipeline, best_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally we evaluate the pipeline:\n",
        "\n",
        "* The precision on Virginica, on the train set, is 98% and on the test set is 100%. It is a very good sign that the precision is maximised for the test set since it shows the pipeline can generalise on unseen data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                      Actual setosa Actual versicolor Actual virginica\n",
            "Prediction setosa                40                 0                0\n",
            "Prediction versicolor             0                36                0\n",
            "Prediction virginica              0                 2               42\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        40\n",
            "  versicolor       1.00      0.95      0.97        38\n",
            "   virginica       0.95      1.00      0.98        42\n",
            "\n",
            "    accuracy                           0.98       120\n",
            "   macro avg       0.98      0.98      0.98       120\n",
            "weighted avg       0.98      0.98      0.98       120\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                      Actual setosa Actual versicolor Actual virginica\n",
            "Prediction setosa                10                 0                0\n",
            "Prediction versicolor             0                12                0\n",
            "Prediction virginica              0                 0                8\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00        12\n",
            "   virginica       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def confusion_matrix_and_report(X,y,pipeline,label_map):\n",
        "\n",
        "  prediction = pipeline.predict(X)\n",
        "\n",
        "  print('---  Confusion Matrix  ---')\n",
        "  print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
        "        columns=[ [\"Actual \" + sub for sub in label_map] ], \n",
        "        index= [ [\"Prediction \" + sub for sub in label_map ]]\n",
        "        ))\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "  print('---  Classification Report  ---')\n",
        "  print(classification_report(y, prediction),\"\\n\")\n",
        "\n",
        "\n",
        "def clf_performance(X_train,y_train,X_test,y_test,pipeline,label_map):\n",
        "  print(\"#### Train Set #### \\n\")\n",
        "  confusion_matrix_and_report(X_train,y_train,pipeline,label_map)\n",
        "\n",
        "  print(\"#### Test Set ####\\n\")\n",
        "  confusion_matrix_and_report(X_test,y_test,pipeline,label_map)\n",
        "    \n",
        "\n",
        "clf_performance(X_train=X_train, y_train=y_train,\n",
        "                X_test=X_test, y_test=y_test,\n",
        "                pipeline=pipeline,\n",
        "                label_map= df_clf['species'].unique()\n",
        "                )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv (3.12.8)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
